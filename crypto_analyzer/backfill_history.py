#!/usr/bin/env python3
"""
Backfill Crypto History - –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É Home Assistant

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python3 backfill_history.py [--days 90]

–í–ê–ñ–ù–û: –ó–∞–ø—É—Å–∫–∞—Ç—å –∫–æ–≥–¥–∞ HA –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ —Å–¥–µ–ª–∞—Ç—å –±—ç–∫–∞–ø –±–∞–∑—ã!
"""

import argparse
import json
import sqlite3
import urllib.request
from datetime import datetime
from pathlib import Path

# –ü—É—Ç–∏ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö HA
DB_PATHS = [
    Path("/config/home-assistant_v2.db"),
    Path("/homeassistant/home-assistant_v2.db"),
    Path(__file__).parent.parent.parent / "home-assistant_v2.db",
]

# –ú–∞–ø–ø–∏–Ω–≥ —Å–µ–Ω—Å–æ—Ä–æ–≤ –Ω–∞ CoinGecko ID
SENSORS_MAP = {
    "sensor.crypto_history_btc_usd": "bitcoin",
    "sensor.crypto_history_eth_usd": "ethereum",
    "sensor.crypto_history_sol_usd": "solana",
    "sensor.crypto_history_ton_usd": "the-open-network",
    "sensor.crypto_history_ar_usd": "arweave",
    "sensor.crypto_history_rndr_usd": "render-token",
    "sensor.crypto_history_fet_usd": "fetch-ai",
    "sensor.crypto_history_tao_usd": "bittensor",
}


def find_db():
    """–ù–∞—Ö–æ–¥–∏—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö HA"""
    for path in DB_PATHS:
        if path.exists():
            return path
    return None


def get_coingecko_history(coin_id: str, days: int = 90) -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω –∏–∑ CoinGecko"""
    url = f"https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart?vs_currency=usd&days={days}&interval=daily"

    try:
        with urllib.request.urlopen(url, timeout=30) as response:
            data = json.loads(response.read())
            # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ [timestamp_ms, price]
            return data.get("prices", [])
    except Exception as e:
        print(f"  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {coin_id}: {e}")
        return []


def get_statistic_id(conn, entity_id: str) -> int:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞—ë—Ç statistic_id –¥–ª—è entity"""
    cursor = conn.cursor()

    # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π
    cursor.execute("SELECT id FROM statistics_meta WHERE statistic_id = ?", (entity_id,))
    row = cursor.fetchone()

    if row:
        return row[0]

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
    cursor.execute(
        """
        INSERT INTO statistics_meta (statistic_id, source, unit_of_measurement, has_mean, has_sum, name)
        VALUES (?, 'recorder', 'USD', 1, 0, ?)
    """,
        (entity_id, entity_id.replace("sensor.", "").replace("_", " ").title()),
    )

    conn.commit()
    return cursor.lastrowid


def insert_statistics(conn, metadata_id: int, prices: list, existing_timestamps: set):
    """–í—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –±–∞–∑—É"""
    cursor = conn.cursor()
    inserted = 0

    for ts_ms, price in prices:
        # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ –Ω–∞—á–∞–ª–∞ —á–∞—Å–∞
        ts = datetime.fromtimestamp(ts_ms / 1000)
        ts_hour = ts.replace(minute=0, second=0, microsecond=0)
        ts_unix = ts_hour.timestamp()

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å
        if ts_unix in existing_timestamps:
            continue

        try:
            cursor.execute(
                """
                INSERT INTO statistics (created_ts, start_ts, mean, min, max, state, sum, metadata_id)
                VALUES (?, ?, ?, ?, ?, ?, NULL, ?)
            """,
                (ts_unix, ts_unix, price, price, price, price, metadata_id),
            )
            inserted += 1
            existing_timestamps.add(ts_unix)
        except sqlite3.IntegrityError:
            pass  # –£–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    conn.commit()
    return inserted


def get_existing_timestamps(conn, metadata_id: int) -> set:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ timestamps –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    cursor = conn.cursor()
    cursor.execute("SELECT start_ts FROM statistics WHERE metadata_id = ?", (metadata_id,))
    return {row[0] for row in cursor.fetchall()}


def main():
    parser = argparse.ArgumentParser(description="Backfill crypto history to HA")
    parser.add_argument("--days", type=int, default=90, help="Days of history to load")
    args = parser.parse_args()

    # –ù–∞—Ö–æ–¥–∏–º –±–∞–∑—É
    db_path = find_db()
    if not db_path:
        print("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö HA –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return

    print(f"üìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_path}")
    print(f"üìÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∑–∞ {args.days} –¥–Ω–µ–π")
    print()

    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∑–∞–Ω—è—Ç–æ–π –±–∞–∑–æ–π
    conn = sqlite3.connect(db_path, timeout=30)
    conn.execute("PRAGMA journal_mode=WAL")
    conn.execute("PRAGMA busy_timeout=30000")

    total_inserted = 0

    for entity_id, coin_id in SENSORS_MAP.items():
        print(f"ü™ô {coin_id.upper()} ({entity_id})")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        prices = get_coingecko_history(coin_id, args.days)
        if not prices:
            print("  ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            continue

        print(f"  üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(prices)} —Ç–æ—á–µ–∫")

        # –ü–æ–ª—É—á–∞–µ–º metadata_id
        metadata_id = get_statistic_id(conn, entity_id)
        print(f"  üîë metadata_id: {metadata_id}")

        # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ timestamps
        existing = get_existing_timestamps(conn, metadata_id)
        print(f"  üìà –£–∂–µ –≤ –±–∞–∑–µ: {len(existing)} —Ç–æ—á–µ–∫")

        # –í—Å—Ç–∞–≤–ª—è–µ–º
        inserted = insert_statistics(conn, metadata_id, prices, existing)
        total_inserted += inserted
        print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {inserted} —Ç–æ—á–µ–∫")
        print()

    conn.close()

    print(f"üéâ –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {total_inserted} —Ç–æ—á–µ–∫")
    print()
    print("‚ö†Ô∏è  –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Home Assistant —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è!")


if __name__ == "__main__":
    main()
