#!/usr/bin/env python3
"""
Final Working Backtest for 2024 Historical Data

This script runs a comprehensive backtest comparing all working ML models
on real historical cryptocurrency data to determine the best performing model.
"""

import asyncio
import json
import logging
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from service.candlestick import CandleInterval, fetch_candlesticks
from service.ml.backtester import ForecastBacktester

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("final_backtest_2024.log"),
    ],
)

logger = logging.getLogger(__name__)


async def run_comprehensive_comparison():
    """Run comprehensive model comparison on historical data."""
    logger.info("=" * 80)
    logger.info("–ó–ê–ü–£–°–ö –§–ò–ù–ê–õ–¨–ù–û–ì–û –ë–≠–ö–¢–ï–°–¢–ê 2024")
    logger.info("=" * 80)

    # Test configuration
    test_symbols = ["BTC/USDT", "ETH/USDT"]
    test_intervals = ["1d"]  # Start with daily for simplicity
    data_limit = 300  # Get more data for better testing

    results = {}

    # Initialize backtester
    backtester = ForecastBacktester()

    for symbol in test_symbols:
        results[symbol] = {}

        for interval in test_intervals:
            logger.info(f"\nüìä –¢–ï–°–¢–ò–†–£–ï–ú {symbol} –Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ {interval}")
            logger.info("-" * 50)

            try:
                # Fetch historical data
                candles = await fetch_candlesticks(symbol=symbol, interval=CandleInterval(interval), limit=data_limit)

                if not candles or len(candles) < 100:
                    logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} {interval}")
                    continue

                prices = [float(candle.close_price) for candle in candles]
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(prices)} —Å–≤–µ—á–µ–π")
                logger.info(f"–ü–µ—Ä–∏–æ–¥: {candles[0].timestamp} - {candles[-1].timestamp}")
                logger.info(f"–¶–µ–Ω—ã: {prices[0]:.2f} ‚Üí {prices[-1]:.2f}")

                # Compare working models (excluding Chronos due to compatibility issues)
                working_models = ["statsforecast", "neuralprophet"]

                comparison = await backtester.compare_models(
                    symbol=symbol,
                    interval=interval,
                    prices=prices,
                    models=working_models,
                    train_ratio=0.6,
                    test_ratio=0.4,
                )

                # Store results
                results[symbol][interval] = {
                    "total_data_points": len(prices),
                    "period_start": candles[0].timestamp,
                    "period_end": candles[-1].timestamp,
                    "price_range": f"{prices[0]:.2f} ‚Üí {prices[-1]:.2f}",
                    "models_tested": len(comparison.metrics),
                    "best_model": comparison.best_model,
                    "metrics": [metric.to_dict() for metric in comparison.metrics],
                }

                # Print detailed results
                logger.info(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –î–õ–Ø {symbol} {interval}:")
                logger.info(f"  –í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö: {len(prices)} —Å–≤–µ—á–µ–π")
                logger.info(f"  –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥: {len(prices) * 0.4:.0f} —Å–≤–µ—á–µ–π")

                for metric in comparison.metrics:
                    direction_emoji = "‚ÜóÔ∏è" if metric.direction_accuracy > 50 else "‚ÜòÔ∏è"
                    logger.info(
                        f"  {metric.model:20} "
                        f"MAE: {metric.mae:8.2f} | "
                        f"RMSE: {metric.rmse:8.2f} | "
                        f"–ù–∞–ø—Ä.—Ç–æ—á–Ω: {metric.direction_accuracy:5.1f}% {direction_emoji}"
                    )

                if comparison.best_model:
                    best_metrics = next(m for m in comparison.metrics if m.model == comparison.best_model)
                    logger.info(f"\nüèÜ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {comparison.best_model}")
                    logger.info(f"   MAE: {best_metrics.mae:.2f}")
                    logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {best_metrics.direction_accuracy:.1f}%")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è {symbol} {interval}: {e}")
                results[symbol][interval] = {"error": str(e)}

    # Save detailed results
    output_file = Path("ml_backtest_results_2024.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, default=str, ensure_ascii=False)

    logger.info(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

    # Print final summary
    print_final_summary(results)

    return results


def print_final_summary(results: dict):
    """Print comprehensive summary of backtest results."""
    logger.info("\n" + "=" * 80)
    logger.info("–ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ë–≠–ö–¢–ï–°–¢–ê 2024")
    logger.info("=" * 80)

    total_tests = 0
    successful_tests = 0
    model_performance = {}

    for symbol, symbol_data in results.items():
        logger.info(f"\nüî∏ {symbol}:")
        logger.info("‚îÄ" * 40)

        for interval, interval_data in symbol_data.items():
            total_tests += 1

            if "error" in interval_data:
                logger.info(f"  {interval}: ‚ùå –û–®–ò–ë–ö–ê - {interval_data['error']}")
                continue

            successful_tests += 1
            logger.info(f"  {interval}: ‚úÖ –£–°–ü–ï–®–ù–û")
            logger.info(f"    –î–∞–Ω–Ω—ã–µ: {interval_data['total_data_points']} —Å–≤–µ—á–µ–π")
            logger.info(f"    –ü–µ—Ä–∏–æ–¥: {interval_data['price_range']}")
            logger.info(f"    –ú–æ–¥–µ–ª–µ–π –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {interval_data['models_tested']}")

            if interval_data["best_model"]:
                logger.info(f"    üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {interval_data['best_model']}")

                # Track model performance across tests
                model = interval_data["best_model"]
                if model not in model_performance:
                    model_performance[model] = 0
                model_performance[model] += 1

    # Overall statistics
    logger.info("\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    logger.info(f"  –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
    logger.info(f"  –£—Å–ø–µ—à–Ω—ã—Ö: {successful_tests}")
    logger.info(
        f"  –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(successful_tests/total_tests)*100:.1f}%" if total_tests > 0 else "  –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: 0%"
    )

    if model_performance:
        logger.info("\nü§ñ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ú–û–î–ï–õ–ï–ô:")
        for model, wins in model_performance.items():
            win_rate = (wins / successful_tests) * 100
            logger.info(f"  {model:20} - –ü–æ–±–µ–¥: {wins} ({win_rate:.1f}%)")

    # Recommendations
    if model_performance:
        best_model = max(model_performance.items(), key=lambda x: x[1])[0]
        logger.info("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:")
        logger.info(f"  –î–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: {best_model}")
        logger.info(
            f"  –≠—Ç–∞ –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑–∞–ª–∞ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {model_performance[best_model]} –∏–∑ {successful_tests} —Ç–µ—Å—Ç–æ–≤"
        )


async def main():
    """Main execution function."""
    try:
        # Run comprehensive backtest
        results = await run_comprehensive_comparison()

        logger.info("\n" + "=" * 80)
        logger.info("‚úÖ –ë–≠–ö–¢–ï–°–¢ 2024 –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        logger.info("=" * 80)
        logger.info("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        logger.info("  - ml_backtest_results_2024.json (–¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)")
        logger.info("  - final_backtest_2024.log (–ª–æ–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)")

        return results

    except Exception as e:
        logger.error(f"‚ùå –§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –±—ç–∫—Ç–µ—Å—Ç–∞: {e}")
        raise


if __name__ == "__main__":
    # Run the backtest
    results = asyncio.run(main())
